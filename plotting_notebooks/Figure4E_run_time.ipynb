{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456febfc-1847-4b7d-aa4e-f2d6e48c81c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "from plotnine_prism import *\n",
    "from tqdm import tqdm\n",
    "import plotnine as p9\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import yaml\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.utils import bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf07baa0-9b63-4b75-9198-535ad00a90b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../model_and_dataset_info.yaml\", \"r\") as stream:\n",
    "    model_and_dataset_info = yaml.safe_load(stream)\n",
    "model_and_dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37fea8-b6e0-4ced-ac3b-52dcff833f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_patterns = [\"maynard_human_brain_analysis\", \"10x_TuPro_v2\"] \n",
    "\n",
    "benchmark_files = []\n",
    "\n",
    "for start_pattern in start_patterns:\n",
    "    current_pattern = f\"../{start_pattern}*/out_benchmark/benchmarks/**/*.log\"\n",
    "    files = glob.glob(current_pattern, recursive=True)\n",
    "    files = [f for f in files if \"evaluate\" in f or \"extract\" in f]\n",
    "    benchmark_files.extend(files)\n",
    "benchmark_files[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f298e288-0083-4161-88b3-cd24016564af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for file in tqdm(benchmark_files):\n",
    "    rule = file.split(\"/\")[4].split(\".log\")[0]\n",
    "    dataset = file.split(\"/\")[1]\n",
    "    df = pd.read_csv(file, sep=\"\\t\")\n",
    "    df[\"rule\"] = rule\n",
    "    df[\"dataset\"] = dataset\n",
    "    data.append(df)\n",
    "data = pd.concat(data)\n",
    "data = data[[\"rule\", \"dataset\", \"s\"]]\n",
    "image_extract = data[data.rule == \"extract_image_features\"].groupby(\"dataset\").s.agg(\"mean\").to_dict()\n",
    "data = data[data.rule != \"extract_image_features\"]\n",
    "data[\"s\"] = data.apply(lambda x: x.s if \"AESTETIK\" != x.rule else x.s + image_extract[x.dataset], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee5c90-fd6b-4671-8f77-0d2473f5aae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab = data.groupby([\"rule\", \"dataset\"]).s.apply(lambda x: bootstrapping(x)).reset_index()\n",
    "tab = pd.DataFrame(tab[\"s\"].to_list(), columns=['value_median', 'value_std'], index=[tab[\"rule\"], tab[\"dataset\"]]).reset_index()\n",
    "tab[\"modality\"] = tab.rule.apply(lambda x: model_and_dataset_info[\"model_modality\"][x])\n",
    "tab[\"model\"] = tab.rule\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f591b5-95da-4e84-b8ab-c146f25077cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab[\"time_min_median\"] = tab.value_median / 60\n",
    "tab[\"time_min_std\"] = tab.value_std / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6736c-88e5-451b-b89f-24603fc04550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(data.groupby([\"rule\"]).s.apply(lambda x: bootstrapping(x)[0]) / 60).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a69e8c-8138-4dd3-9e4d-e3dfa9d48065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab[\"Dataset\"] = tab.dataset.apply(lambda x: model_and_dataset_info[\"dataset\"][x])\n",
    "\n",
    "tab = tab.query(\"rule in ['SpaGCN', 'BayesSpace', 'AESTETIK', 'GraphST', 'STAGATE', 'MUSE', 'Leiden', 'stLearn']\")\n",
    "tab.Dataset = pd.Categorical(tab.Dataset, ['LIBD Human DLPFC','Tumor Profiler'])\n",
    "\n",
    "tab[\"model_rank\"] = tab.groupby(\"dataset\").value_median.rank(ascending=False)\n",
    "tab.model = pd.Categorical(tab.model, tab.groupby(\"model\").model_rank.agg(\"median\").sort_values().index)\n",
    "\n",
    "position_dodge_width = 0.8\n",
    "tab[\"Model\"] = tab.model\n",
    "\n",
    "tab[\"modality\"] = pd.Categorical(tab[\"modality\"], ['transcriptomics', \n",
    "                                  'transcriptomics + spatial', \n",
    "                                  'transcriptomics + image', \n",
    "                                  'transcriptomics + spatial + image'])\n",
    "\n",
    "\n",
    "tab[\"Modality\"] = tab.modality.apply(lambda x: 'transcriptomics + spatial + image' if x == 'transcriptomics + spatial + image' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2592dc-b465-4bf7-a300-c05655fb7f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = (p9.ggplot(tab, p9.aes(\"Dataset\", \"time_min_median\")) \n",
    " + p9.geom_point(p9.aes(color=\"Model\", shape=\"Modality\"), size=3, position=p9.position_dodge(width=position_dodge_width)) \n",
    " + p9.facet_grid(\"~Dataset\", scales=\"free_x\")\n",
    " + p9.geom_errorbar(p9.aes(x=\"Dataset\", ymin=\"time_min_median-time_min_std\",ymax=\"time_min_median+time_min_std\", color=\"Model\"), \n",
    "                    width=0.001, alpha=1, size=1,\n",
    "                   position=p9.position_dodge(width=position_dodge_width))\n",
    " + p9.theme_bw()\n",
    " + p9.theme(subplots_adjust={'wspace': 0}, figure_size=(8, 5), axis_text_x = p9.element_blank(), \n",
    "            legend_position=\"right\",\n",
    "            text=p9.element_text(size=15),\n",
    "            strip_text=p9.element_text(size=17),\n",
    "            legend_title=p9.element_text(size=17),\n",
    "            legend_text=p9.element_text(size=16))\n",
    " + p9.ylab(\"Time (min)\")\n",
    " + p9.xlab(\"\")\n",
    " + scale_color_prism(palette = \"colors\")\n",
    " + p9.guides(color=p9.guide_legend(nrow=4, override_aes = p9.aes(shape = \".\")))\n",
    " + p9.scale_y_continuous(breaks=list(np.arange(0, int(tab['time_min_median'].max())+5, 5)))\n",
    ")\n",
    "p.save(\"figures/run_time.png\", dpi=300)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db7ac95-831a-4b24-8030-d51ae3dc4748",
   "metadata": {},
   "outputs": [],
   "source": [
    "hline_tab = tab.groupby([\"Modality\", \"dataset\"]).value_median.agg(\"median\").reset_index()\n",
    "hline_tab[\"modality_dataset\"] = hline_tab.apply(lambda x: f\"{x.Modality}_{x.dataset}\", axis=1)\n",
    "hline_tab[\"hline_value_median\"] = hline_tab[\"value_median\"]\n",
    "hline_tab.drop({\"value_median\"}, axis=1, inplace=True)\n",
    "hline_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbacc44-f9ed-48f6-923a-534524dcc4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nonchev",
   "language": "python",
   "name": "nonchev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
